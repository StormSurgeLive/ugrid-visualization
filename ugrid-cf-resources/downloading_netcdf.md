# Downloading ADCIRC NetCDF Output Files from a THREDDS Server

## Background

ADCIRC netCDF output files generated by the ASGS (https://github.com/StormSurgeLive/asgs) are stored on public THREDDS servers[^1] and can be downloaded in a straightforward way from a Unix shell by using a utility such as `wget`. However, timeseries files such as fort.63 and fort.74 can be very large, so it's convenient to be able to download a subset of these files for a reduced number of timesteps. This document will show how to achieve this using the `ncks` utility from the NetCDF Operators package.

## Software requirements

To follow along with the examples in this document, you'll need to download some command-line tools for working with netCDF. On
Ubuntu Linux, you can download these tools with the following command:

```
$ sudo apt install nco
```
You may need to run `sudo apt update && sudo apt upgrade` beforehand if the package can't be found. The `nco` (NetCDF Operators) package includes the `ncks` utility which will be used for the examples in this document.

On Mac, the following command should work to install `nco`:
```
$ brew install nco
```

## Downloading an entire fort.63 file

Suppose we want to download a fort.63 file for Hurricane Laura (2020). If you follow this link 
```
https://fortytwo.cct.lsu.edu/thredds/catalog/2020/laura/27/CTXCS2017/qbc.loni.org/CTXCS2017_al132020_jgf/nhcConsensus/catalog.html?dataset=2020/laura/27/CTXCS2017/qbc.loni.org/CTXCS2017_al132020_jgf/nhcConsensus/fort.63.nc
```
on a browser, you can see different options for accessing a fort.63 for Hurricane Laura's advisory 27. 

If you copy the URL from the HTTPServer option, you could download the entire file with the following command:
```
$ wget https://fortytwo.cct.lsu.edu/thredds/fileServer/2020/laura/27/CTXCS2017/qbc.loni.org/CTXCS2017_al132020_jgf/nhcConsensus/fort.63.nc
```
However, since the fort.63 file is almost 2 GB in size, it may take a while for the download to complete. The fort.74 file for this advisory is even larger, at around 6 GB, showing the need for being able to download subsets in order to save time and storage space.

## Using `ncks` to download a subset of a fort.63 file

This time, instead of using the URL from the HTTPServer access option, you'll need to copy the URL from the OPENDAP[^2] option. To get this URL, first click on the link in the OPENDAP access option, and you should be taken to an "OPeNDAP Dataset Access Form". The URL you need to copy is in the "Data URL" field of the form.

Using this URL, you can run the following command to download a subset of the fort.63 file for only the first 20 timesteps:
```
$ ncks -7 -h -L 5 -d time,0,9 -d time,10,19 'http://fortytwo.cct.lsu.edu/thredds/dodsC/2020/laura/27/CTXCS2017/qbc.loni.org/CTXCS2017_al132020_jgf/nhcConsensus/fort.63.nc' -o fort.63.nc
```
The size of the resulting file should be around 387 MB (compared to the 2 GB total file size). Note that the time subsetting is done in two parts (`-d time,0,9 -d time,10,19`) rather than in one (`-d time 0,19`), but the result is still one file with 20 timesteps. This is done because a 20-timestep subset of this fort.63 is too large for the THREDDS server we're downloading from to transfer at once. If you're donwloading from a different THREDDS server, the limit of data that can be transferred at once may be higher. However, the `ncks` utility makes it simple to split a subset into smaller subsets within the same command (as seen in the command above), so if you get an error message about downloading a subset that's too large, try splitting it into smaller subsets until the command runs.

Other important `ncks` options are:
* `-h` - When using a utility from the `nco` package, the `-h` flag can be included to prevent the command you ran to be added to the file's `history` global attribute. If you do want to have a record of that command, you can remove the `-h` flag.
* `-7` - Specifies that the downloaded file should be in "NetCDF-4 classsic" format.
* `-L 5` - Specifies a compression level of 5, which is used to reduce the file size. Without compression, downloads with `ncks` can result in very large files.
* `-o filename` - Stores the result of the download in a file named `filename`.

In this case, you can use the same `ncks` options to download a 20-timestep subset of the fort.74 file corresponding to the same Hurricane Laura advisory:
```
$ ncks -7 -h -L 5 -d time,0,9 -d time,10,19 'http://fortytwo.cct.lsu.edu/thredds/dodsC/2020/laura/27/CTXCS2017/qbc.loni.org/CTXCS2017_al132020_jgf/nhcConsensus/fort.74.nc' -o fort.74.nc
```
The size of the resulting file should be around 1.1 GB (compared to the 6 GB total file size).

[^1]: For background reading see: https://www.unidata.ucar.edu/software/tds/current/TDS.html
[^2]: For background reading see: https://www.opendap.org/about
